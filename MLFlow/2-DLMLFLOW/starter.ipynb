{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99e26e86",
   "metadata": {},
   "source": [
    "### Quickstart: Compare runs, choose a model, and deploy it to a REST API\n",
    "\n",
    "In this quickstart, you will:\n",
    "\n",
    "- Run a hyperparameter sweep on a training script\n",
    "\n",
    "- Compare the results of the runs in the MLflow UI\n",
    "\n",
    "- Choose the best run and register it as a model\n",
    "\n",
    "- Deploy the model to a REST API\n",
    "\n",
    "- Build a container image suitable for deployment to a cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36faab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6dd1368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the dataset\n",
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\",\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0adcbd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.036</td>\n",
       "      <td>46.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.99300</td>\n",
       "      <td>3.03</td>\n",
       "      <td>0.48</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.27</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.024</td>\n",
       "      <td>13.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.98930</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.51</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.32</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.048</td>\n",
       "      <td>47.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>0.99282</td>\n",
       "      <td>3.21</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3066</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12.30</td>\n",
       "      <td>0.038</td>\n",
       "      <td>77.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.99778</td>\n",
       "      <td>2.95</td>\n",
       "      <td>0.48</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.34</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.040</td>\n",
       "      <td>41.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.99634</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.59</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.52</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.047</td>\n",
       "      <td>28.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.99418</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.32</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0.039</td>\n",
       "      <td>54.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.43</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.043</td>\n",
       "      <td>28.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.99129</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3772</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.035</td>\n",
       "      <td>53.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99567</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.38</td>\n",
       "      <td>10.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.030</td>\n",
       "      <td>38.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.99255</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4163 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1235            7.8              0.32         0.31            1.70      0.036   \n",
       "1108            6.1              0.29         0.27            1.70      0.024   \n",
       "3945            6.2              0.27         0.32            6.30      0.048   \n",
       "3066            7.4              0.21         0.80           12.30      0.038   \n",
       "2960            7.7              0.11         0.34           14.05      0.040   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4426            6.2              0.21         0.52            6.50      0.047   \n",
       "466             7.0              0.14         0.32            9.00      0.039   \n",
       "3092            7.6              0.27         0.52            3.20      0.043   \n",
       "3772            6.3              0.24         0.29           13.70      0.035   \n",
       "860             8.1              0.27         0.35            1.70      0.030   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1235                 46.0                 195.0  0.99300  3.03       0.48   \n",
       "1108                 13.0                  76.0  0.98930  3.21       0.51   \n",
       "3945                 47.0                 159.0  0.99282  3.21       0.60   \n",
       "3066                 77.0                 183.0  0.99778  2.95       0.48   \n",
       "2960                 41.0                 114.0  0.99634  3.07       0.59   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4426                 28.0                 123.0  0.99418  3.22       0.49   \n",
       "466                  54.0                 141.0  0.99560  3.22       0.43   \n",
       "3092                 28.0                 152.0  0.99129  3.02       0.53   \n",
       "3772                 53.0                 134.0  0.99567  3.17       0.38   \n",
       "860                  38.0                 103.0  0.99255  3.22       0.63   \n",
       "\n",
       "      alcohol  quality  \n",
       "1235     10.5        5  \n",
       "1108     12.6        7  \n",
       "3945     11.0        6  \n",
       "3066      9.0        5  \n",
       "2960     11.0        7  \n",
       "...       ...      ...  \n",
       "4426      9.9        6  \n",
       "466       9.4        6  \n",
       "3092     11.4        6  \n",
       "3772     10.6        6  \n",
       "860      10.4        8  \n",
       "\n",
       "[4163 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Split the data into training, validation and testset\n",
    "\n",
    "train, test = train_test_split(data, test_size = 0.15, random_state = 42)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b34f3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop([\"quality\"], axis = 1).values\n",
    "train_y = train[[\"quality\"]].values.ravel() # ravel will make 1 dim\n",
    "\n",
    "## Validation dataset\n",
    "test_x = test.drop([\"quality\"], axis = 1).values\n",
    "test_y = test[[\"quality\"]].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c61642",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = train_test_split(train_x,train_y, test_size=0.15, random_state=42)\n",
    "\n",
    "signature =  infer_signature(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e2ddaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN model\n",
    "\n",
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x,test_y):\n",
    "\n",
    "    ## Define model architechture\n",
    "    mean = np.mean(train_x, axis = 0) # axis = 0 means column with mean\n",
    "    var = np.var(train_x, axis = 0)\n",
    "\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input([train_x.shape[1]]),\n",
    "            keras.layers.Normalization(mean=mean, variance=var),\n",
    "            keras.layers.Dense(64,activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ## Compile the model\n",
    "    model.compile(\n",
    "        optimizer = keras.optimizers.SGD(learning_rate=params[\"lr\"],\n",
    "                                         momentum=params[\"momentum\"]),\n",
    "        loss = \"mean_squared_error\",\n",
    "        metrics = [keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "    ## Train the ANN model with lr and momentum params with MLFLOW tracking\n",
    "    with mlflow.start_run(nested = True):\n",
    "        model.fit(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            validation_data = (valid_x,valid_y),\n",
    "            epochs = epochs,\n",
    "            batch_size = 64\n",
    "        )\n",
    "\n",
    "        ## Evaluate the model\n",
    "        eval_result = model.evaluate(valid_x,valid_y, batch_size = 64)\n",
    "\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        ## Log the parameters and results\n",
    "        mlflow.log_params(params)\n",
    "        mlflow.log_metric(\"Eval_rmse\", eval_rmse)\n",
    "\n",
    "        ## Log the model\n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {\"loss\": eval_rmse, \"status\": STATUS_OK, \"model\": model}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a8eb1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x = train_x,\n",
    "        train_y=train_y,\n",
    "        valid_x = valid_x,\n",
    "        valid_y = valid_y,\n",
    "        test_x = test_x,\n",
    "        test_y=test_y\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d09bfef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    \"lr\":hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    \"momentum\": hp.uniform(\"momentum\",0.0,0.1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bba97948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 02:47:16 INFO mlflow.tracking.fluent: Experiment with name '/wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53s\u001b[0m 980ms/step - loss: 30.9320 - root_mean_squared_error: 5.5617\n",
      "\u001b[1m22/56\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.7009 - root_mean_squared_error: 4.0151   \n",
      "\u001b[1m48/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.3409 - root_mean_squared_error: 3.2493\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 10.3446 - root_mean_squared_error: 3.0904 - val_loss: 1.6072 - val_root_mean_squared_error: 1.2678\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 1.2381 - root_mean_squared_error: 1.1127\n",
      "\u001b[1m27/56\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3225 - root_mean_squared_error: 1.1498 \n",
      "\u001b[1m55/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3123 - root_mean_squared_error: 1.1454\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.3109 - root_mean_squared_error: 1.1448 - val_loss: 1.2265 - val_root_mean_squared_error: 1.1075\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 1.1974 - root_mean_squared_error: 1.0943\n",
      "\u001b[1m25/56\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0488 - root_mean_squared_error: 1.0236 \n",
      "\u001b[1m52/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0045 - root_mean_squared_error: 1.0018\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.0020 - root_mean_squared_error: 1.0005 - val_loss: 0.9803 - val_root_mean_squared_error: 0.9901\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 1.1041 - root_mean_squared_error: 1.0508\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.9650 - root_mean_squared_error: 0.9819 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 649ms/step - loss: 37.3067 - root_mean_squared_error: 6.1079\n",
      "\u001b[1m14/56\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 32.1809 - root_mean_squared_error: 5.6666   \n",
      "\u001b[1m31/56\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.4177 - root_mean_squared_error: 5.2146\n",
      "\u001b[1m55/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 22.7826 - root_mean_squared_error: 4.7251\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 22.4782 - root_mean_squared_error: 4.6911 - val_loss: 3.8470 - val_root_mean_squared_error: 1.9614\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - loss: 2.9628 - root_mean_squared_error: 1.7213\n",
      "\u001b[1m29/56\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1866 - root_mean_squared_error: 1.7847 \n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.9994 - root_mean_squared_error: 1.7307 - val_loss: 2.1903 - val_root_mean_squared_error: 1.4800\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - loss: 1.9305 - root_mean_squared_error: 1.3894\n",
      "\u001b[1m17/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.2461 - root_mean_squared_error: 1.4981 \n",
      "\u001b[1m24/56\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2331 - root_mean_squared_error: 1.4939\n",
      "\u001b[1m35/56\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 2.2254 - root_mean_squared_error: 1.4915\n",
      "\u001b[1m51/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 2.1872 - root_mean_squared_error: 1.4786\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 2.1711 - root_mean_squared_error: 1.4730 - val_loss: 1.8807 - val_root_mean_squared_error: 1.3714\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 1.9175 - root_mean_squared_error: 1.3847\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.7824 - root_mean_squared_error: 1.3346 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 526ms/step - loss: 35.5421 - root_mean_squared_error: 5.9617\n",
      "\u001b[1m32/56\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.4800 - root_mean_squared_error: 4.5883   \n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 16.6847 - root_mean_squared_error: 3.9975 - val_loss: 2.1452 - val_root_mean_squared_error: 1.4647\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 1.8981 - root_mean_squared_error: 1.3777\n",
      "\u001b[1m26/56\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9485 - root_mean_squared_error: 1.3957 \n",
      "\u001b[1m54/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.9093 - root_mean_squared_error: 1.3815\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9058 - root_mean_squared_error: 1.3803 - val_loss: 1.7264 - val_root_mean_squared_error: 1.3139\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 122ms/step - loss: 1.3848 - root_mean_squared_error: 1.1768\n",
      "\u001b[1m18/56\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5046 - root_mean_squared_error: 1.2260  \n",
      "\u001b[1m51/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5210 - root_mean_squared_error: 1.2330\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.5190 - root_mean_squared_error: 1.2322 - val_loss: 1.5038 - val_root_mean_squared_error: 1.2263\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4866 - root_mean_squared_error: 1.2193\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4562 - root_mean_squared_error: 1.2065 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 571ms/step - loss: 42.4698 - root_mean_squared_error: 6.5169\n",
      "\u001b[1m32/56\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.7001 - root_mean_squared_error: 4.2064   \n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 13.6158 - root_mean_squared_error: 3.5285 - val_loss: 1.5901 - val_root_mean_squared_error: 1.2610\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.8472 - root_mean_squared_error: 0.9204\n",
      "\u001b[1m25/56\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2177 - root_mean_squared_error: 1.1024 \n",
      "\u001b[1m53/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2622 - root_mean_squared_error: 1.1228\n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.2619 - root_mean_squared_error: 1.1227 - val_loss: 1.1862 - val_root_mean_squared_error: 1.0891\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/56\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 1.0225 - root_mean_squared_error: 1.0112\n",
      "\u001b[1m30/56\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0664 - root_mean_squared_error: 1.0325 \n",
      "\u001b[1m56/56\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.0420 - root_mean_squared_error: 1.0206 - val_loss: 1.0080 - val_root_mean_squared_error: 1.0040\n",
      "\n",
      "\u001b[1m 1/10\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.1948 - root_mean_squared_error: 1.0931\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.9914 - root_mean_squared_error: 0.9950 \n",
      "\n",
      "100%|██████████| 4/4 [01:03<00:00, 15.86s/trial, best loss: 0.9900819659233093]\n",
      "Best parameters: {'lr': np.float64(0.008701156446060902), 'momentum': np.float64(0.09699590996526014)}\n",
      "Best eval rmse: 0.9900819659233093\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn = objective,\n",
    "        space = space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals = 4,\n",
    "        trials = trials\n",
    "    )\n",
    "\n",
    "    # Fetch the details of the best run\n",
    "    best_run = sorted(trials.results, key = lambda x : x[\"loss\"])[0]\n",
    "\n",
    "    # Log the best parameters, loss, and model\n",
    "    mlflow.log_params(best)\n",
    "    mlflow.log_metric(\"eval_rmse\",best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run[\"model\"], \"model\", signature=signature)\n",
    "\n",
    "    # Print out the best parameters and corresponding loss\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best eval rmse: {best_run['loss']}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e92f155",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/13 02:57:09 INFO mlflow.models.python_api: It is highly recommended to use `uv` as the environment manager for predicting with MLflow models as its performance is significantly better than other environment managers. Run `pip install uv` to install uv. See https://docs.astral.sh/uv/getting-started/installation for other installation methods.\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 583.68it/s] \n",
      "2025/05/13 02:57:09 INFO mlflow.models.flavor_backend_registry: Selected backend for flavor 'python_function'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "{\"predictions\": [[5.330509185791016], [6.678794860839844], [6.3922929763793945], [4.972773551940918], [5.678166389465332], [6.777868270874023], [5.852817535400391], [5.625035285949707], [6.442533493041992], [6.591113090515137], [6.954345703125], [4.547308921813965], [6.8898468017578125], [4.770693778991699], [6.216418266296387], [5.046977996826172], [7.3248186111450195], [6.379878997802734], [6.0762128829956055], [5.519220352172852], [5.537153244018555], [6.552518844604492], [4.591621398925781], [5.391119956970215], [5.284780502319336], [4.739828109741211], [4.624824047088623], [6.078740119934082], [5.892329216003418], [4.515091419219971], [5.786224365234375], [5.136102676391602], [6.594532012939453], [4.903541088104248], [5.775080680847168], [6.226853370666504], [7.061994552612305], [5.164926528930664], [5.534799575805664], [5.990505218505859], [5.5212907791137695], [4.982534408569336], [5.311834335327148], [5.597153663635254], [4.69978141784668], [6.215925216674805], [5.4187774658203125], [6.224008560180664], [5.403058052062988], [5.623467445373535], [4.779627799987793], [6.619782447814941], [6.2365827560424805], [6.041121482849121], [5.688467979431152], [5.761148452758789], [6.370907783508301], [5.252514362335205], [5.770998954772949], [5.799093246459961], [5.6165056228637695], [7.169732093811035], [5.093659400939941], [7.1096906661987305], [6.019129753112793], [6.377782821655273], [6.255243301391602], [6.208854675292969], [5.801243782043457], [4.606178283691406], [4.603156089782715], [5.496075630187988], [5.461101531982422], [4.084722518920898], [5.6411027908325195], [5.908474922180176], [6.161182403564453], [5.302706718444824], [7.995755195617676], [6.217157363891602], [5.514674186706543], [5.676017761230469], [5.534191131591797], [4.18602180480957], [6.338861465454102], [6.149845123291016], [5.036193370819092], [5.755983352661133], [6.520551681518555], [6.172968864440918], [6.669665336608887], [5.723350524902344], [5.184920310974121], [7.076629638671875], [6.4692182540893555], [6.646061897277832], [6.505032539367676], [5.474850654602051], [4.6115217208862305], [6.809513092041016], [5.082171440124512], [6.322138786315918], [6.22083854675293], [4.804146766662598], [7.1804046630859375], [5.181724548339844], [5.799093246459961], [5.757081985473633], [6.379878997802734], [5.9072675704956055], [6.070128440856934], [6.625306129455566], [6.533952713012695], [5.669084548950195], [4.896021842956543], [6.702637672424316], [6.883648872375488], [6.874547004699707], [5.8784284591674805], [6.213584899902344], [5.387811660766602], [6.878150939941406], [6.4405412673950195], [5.101025104522705], [5.681269645690918], [5.860547065734863], [7.209405899047852], [5.021899700164795], [7.080632209777832], [5.671483039855957], [6.590785026550293], [5.782074928283691], [5.7503204345703125], [5.797808647155762], [4.421387672424316], [6.024202346801758], [4.745087623596191], [5.058794975280762], [6.69620418548584], [4.751628875732422], [6.748441696166992], [5.973876953125], [5.161869049072266], [5.650774002075195], [4.998081207275391], [5.261731147766113], [4.16553258895874], [5.038360595703125], [5.966066360473633], [4.884415626525879], [6.897520065307617], [5.675361633300781], [6.248721122741699], [6.603951454162598], [5.504566192626953], [4.676741600036621], [6.414809226989746], [6.961454391479492], [5.654809951782227], [6.384428977966309], [6.083883285522461], [4.919858932495117], [5.892146110534668], [5.489265441894531], [5.339842796325684], [5.9966840744018555], [4.986976623535156], [6.163243293762207], [5.758732795715332], [5.570159912109375], [5.028115272521973], [5.751718521118164], [6.074594497680664], [4.603238582611084], [7.006439208984375], [5.250004768371582], [6.478392601013184], [5.713597297668457], [5.789786338806152], [4.779151916503906], [6.926100730895996], [6.385148048400879], [4.975019931793213], [5.667555809020996], [4.463908672332764], [4.9984130859375], [5.622104644775391], [5.002171516418457], [6.19558048248291], [7.260475158691406], [5.097667694091797], [5.513449668884277], [5.64656925201416], [6.805093765258789], [4.99798059463501], [5.751459121704102], [6.861604690551758], [6.2683916091918945], [5.003401756286621], [5.799771308898926], [5.316760063171387], [4.791742324829102], [6.986001968383789], [5.524928092956543], [5.528749465942383], [5.304233551025391], [7.710439682006836], [5.662999153137207], [5.678461074829102], [6.032168388366699], [5.867596626281738], [7.022921562194824], [5.832542419433594], [5.9349517822265625], [4.836644172668457], [6.569770812988281], [5.799592971801758], [8.083662986755371], [7.169732093811035], [6.509712219238281], [5.834576606750488], [5.81622314453125], [5.13478946685791], [6.199345588684082], [6.821174621582031], [5.904766082763672], [5.916504859924316], [6.886445999145508], [6.420881271362305], [5.234813690185547], [5.301697254180908], [5.438549995422363], [5.561182975769043], [5.415937423706055], [4.939453125], [8.347543716430664], [5.796109199523926], [5.67460823059082], [5.149306297302246], [4.8956298828125], [5.677130699157715], [6.472871780395508], [7.006298065185547], [5.878000259399414], [6.416930198669434], [4.855978965759277], [6.603046417236328], [4.033184051513672], [5.926571846008301], [5.066083908081055], [5.9042253494262695], [6.668346405029297], [5.379075050354004], [5.022790908813477], [5.4272003173828125], [4.883444309234619], [5.657046318054199], [6.145145416259766], [5.63859748840332], [5.643315315246582], [5.914952278137207], [4.628127098083496], [5.687239646911621], [4.388960838317871], [6.254635810852051], [5.866715431213379], [5.410549163818359], [5.1988301277160645], [6.021839141845703], [5.516489028930664], [7.8940534591674805], [5.620085716247559], [6.492178916931152], [6.930320739746094], [4.517945289611816], [5.946124076843262], [6.0956573486328125], [5.623939514160156], [6.099334716796875], [6.706146240234375], [5.402860641479492], [5.6411027908325195], [6.681427001953125], [5.817849159240723], [5.780470848083496], [6.384121894836426], [7.801387786865234], [5.66290283203125], [5.921299934387207], [4.697619438171387], [6.170517921447754], [5.826149940490723], [5.944501876831055], [4.801545143127441], [6.188843727111816], [6.366477012634277], [6.0355634689331055], [5.997929573059082], [6.308846473693848], [5.324180603027344], [4.779627799987793], [5.16592264175415], [9.318410873413086], [5.20477294921875], [7.390469551086426], [5.267679214477539], [5.323139190673828], [5.392162322998047], [6.7765092849731445], [5.680761337280273], [5.378812789916992], [6.66120719909668], [4.992447853088379], [6.579075813293457], [5.802704811096191], [6.629449844360352], [5.359784126281738], [6.498965263366699], [5.192383766174316], [6.145661354064941], [5.342164993286133], [6.022979736328125], [6.5790605545043945], [6.316062927246094], [5.803867340087891], [5.019704818725586], [6.532282829284668], [6.012870788574219], [8.182647705078125], [6.295117378234863], [5.2111029624938965], [6.654540061950684], [6.995603561401367], [6.114200592041016], [6.224145889282227], [5.881404876708984], [7.051197052001953], [6.262746810913086], [5.730456352233887], [4.9632158279418945], [5.993358612060547], [5.791872978210449], [5.500820159912109], [7.0997314453125], [5.190993309020996], [5.708835601806641], [7.385972023010254], [6.081242561340332], [6.508170127868652], [5.551027297973633], [6.8827314376831055], [6.079409599304199], [7.1804046630859375], [4.722373962402344], [6.380740165710449], [5.022790908813477], [6.080659866333008], [5.789916038513184], [7.167057991027832], [6.6869001388549805], [5.409921646118164], [5.967850685119629], [5.254377365112305], [5.354123115539551], [5.906126022338867], [5.920441627502441], [6.191468238830566], [5.232827186584473], [5.218009948730469], [6.023867607116699], [4.688137054443359], [5.1537322998046875], [5.280788898468018], [6.1213178634643555], [6.751418113708496], [5.577056884765625], [6.774019241333008], [4.504158973693848], [5.880166053771973], [6.112715721130371], [6.046016693115234], [5.516392707824707], [6.205318450927734], [6.452735900878906], [5.038845062255859], [6.474864959716797], [5.2376179695129395], [4.963618278503418], [6.252015113830566], [5.540593147277832], [4.5780134201049805], [6.015522003173828], [4.998652458190918], [5.188778877258301], [5.767294883728027], [5.8130035400390625], [5.335933685302734], [5.4206390380859375], [6.211104393005371], [5.0029215812683105], [5.7907609939575195], [6.987934112548828], [5.475647926330566], [6.17659854888916], [5.562290191650391], [5.26754093170166], [6.6688995361328125], [5.1173295974731445], [6.102840423583984], [6.308376312255859], [4.801545143127441], [4.911266326904297], [6.9118852615356445], [5.013487815856934], [5.688727378845215], [5.489017486572266], [5.367316246032715], [5.903076171875], [4.880062103271484], [6.367535591125488], [6.431037902832031], [5.543208122253418], [5.5655622482299805], [5.922050476074219], [6.914491653442383], [5.774621963500977], [5.548816680908203], [6.34757137298584], [6.121489524841309], [6.215723991394043], [5.92786979675293], [4.9815263748168945], [4.555967330932617], [6.338706970214844], [6.467522621154785], [5.090262413024902], [5.890336036682129], [6.998353004455566], [4.413695335388184], [6.99977970123291], [5.912995338439941], [7.228730201721191], [5.908474922180176], [5.189610481262207], [5.503381729125977], [6.29670524597168], [6.248373031616211], [5.4830474853515625], [3.968630790710449], [6.095877647399902], [4.16873836517334], [5.68449592590332], [6.071523666381836], [6.6314897537231445], [6.170805931091309], [6.068380355834961], [5.393044471740723], [6.653423309326172], [4.622668266296387], [5.289557456970215], [6.549638748168945], [6.840483665466309], [5.97552490234375], [5.468486785888672], [6.072737693786621], [7.034460067749023], [5.97674560546875], [6.370820999145508], [6.525354385375977], [6.378884315490723], [4.257312774658203], [7.291049003601074], [6.23089599609375], [4.853209972381592], [4.382944107055664], [6.295001029968262], [5.4598894119262695], [4.875744819641113], [6.3169355392456055], [5.257538795471191], [4.945775985717773], [5.560619354248047], [5.586217880249023], [5.602138519287109], [4.798501491546631], [6.087196350097656], [5.5325422286987305], [6.353531837463379], [6.0923919677734375], [7.02756404876709], [5.953049659729004], [4.452109336853027], [6.527515411376953], [5.164046287536621], [6.843745231628418], [6.687155723571777], [5.466730117797852], [4.883444786071777], [6.131566047668457], [4.763455390930176], [6.5755414962768555], [4.998383522033691], [5.883342742919922], [6.455879211425781], [5.147037506103516], [5.637076377868652], [6.182106018066406], [6.345163345336914], [5.326228141784668], [6.407841682434082], [6.113739013671875], [4.993051528930664], [4.5997114181518555], [6.203253746032715], [5.044898986816406], [5.368983268737793], [5.478838920593262], [5.196537017822266], [4.614660263061523], [4.721148490905762], [4.720479965209961], [5.018128395080566], [6.113574028015137], [4.786160469055176], [5.146730422973633], [5.136102676391602], [5.984063148498535], [5.36452579498291], [4.806398868560791], [15.698765754699707], [6.534830093383789], [5.6535234451293945], [5.036193370819092], [5.676872253417969], [5.525668144226074], [5.561922073364258], [6.5183563232421875], [8.42525863647461], [6.749052047729492], [5.866572380065918], [4.876906394958496], [4.760727882385254], [6.051468849182129], [5.634809494018555], [6.584589004516602], [4.933658123016357], [5.963034629821777], [5.18105411529541], [5.0323309898376465], [5.325716972351074], [4.963583946228027], [6.620082855224609], [5.8834943771362305], [4.58650016784668], [7.006439208984375], [6.503970146179199], [6.376842498779297], [7.08616828918457], [4.608455657958984], [5.602910041809082], [6.399989128112793], [5.379392623901367], [5.995331764221191], [5.904415130615234], [5.884531021118164], [5.571979522705078], [6.118154525756836], [5.599408149719238], [6.4856672286987305], [4.455423355102539], [5.4705047607421875], [6.058032989501953], [5.577915191650391], [5.375528335571289], [5.167403221130371], [5.950468063354492], [5.993509292602539], [5.326228141784668], [6.612033843994141], [6.8947248458862305], [5.002753257751465], [6.889925003051758], [5.896162986755371], [5.295926094055176], [5.4190216064453125], [4.680597305297852], [5.637784004211426], [4.965982437133789], [5.301116943359375], [5.964350700378418], [5.880166053771973], [6.460433006286621], [4.698862075805664], [7.842004776000977], [6.03754997253418], [5.845955848693848], [6.78499698638916], [6.328824043273926], [5.974989891052246], [5.647871017456055], [5.403058052062988], [6.611235618591309], [6.446836471557617], [7.133450508117676], [5.926738739013672], [8.289177894592285], [5.301207542419434], [6.469211578369141], [6.1213178634643555], [5.961976051330566], [5.767059326171875], [6.816103935241699], [6.167563438415527], [5.373512268066406], [5.677793502807617], [5.850916862487793], [5.18967342376709], [6.180251121520996], [5.2398223876953125], [5.471196174621582], [5.892329216003418], [6.396340370178223], [4.655271530151367], [5.669589996337891], [6.6136322021484375], [5.476099967956543], [6.022979736328125], [5.723623275756836], [6.227114677429199], [6.023284912109375], [4.155927658081055], [4.982534408569336], [5.9556379318237305], [5.602602958679199], [5.258537292480469], [5.841912269592285], [6.278420448303223], [5.362287521362305], [5.156031608581543], [5.5194292068481445], [5.035499095916748], [7.089529037475586], [6.200958251953125], [5.013189315795898], [5.612709999084473], [4.656627655029297], [5.452905654907227], [5.529667854309082], [6.492178916931152], [5.570169448852539], [7.418120384216309], [5.74379825592041], [5.585536003112793], [5.886823654174805], [6.503970146179199], [5.325716972351074], [5.296804428100586], [4.830466270446777], [5.2523956298828125], [6.004911422729492], [7.871328353881836], [6.571953773498535], [6.832671165466309], [5.391119956970215], [5.233368873596191], [6.691682815551758], [6.581855773925781], [4.89637565612793], [6.662951469421387], [5.355463981628418], [6.309488296508789], [5.91197395324707], [4.5572662353515625], [6.285815238952637], [6.876466751098633], [6.02519416809082], [4.78720760345459], [7.842004776000977], [5.522095680236816], [6.195888519287109], [5.985960960388184], [5.614584922790527], [6.149016380310059], [6.573726654052734], [6.170249938964844], [5.271206855773926], [6.070956230163574], [5.8212995529174805], [6.200040817260742], [5.451869964599609], [5.996587753295898], [5.753557205200195], [5.623467445373535], [7.060481071472168], [7.603310585021973], [7.871328353881836], [4.8348894119262695], [5.433263778686523], [6.787583351135254], [6.43107795715332], [5.202176094055176], [5.423980712890625], [4.882840156555176], [6.587018966674805], [5.2940802574157715], [5.617830276489258], [7.006507873535156], [6.310185432434082], [4.716723442077637], [4.649150848388672], [4.894996643066406], [6.601005554199219], [6.716782569885254], [6.6248931884765625], [5.132197380065918], [5.330929756164551], [5.840124130249023], [6.047879219055176], [6.278402328491211], [5.926637649536133], [4.168676853179932], [6.118281364440918], [5.66943359375], [6.492685317993164], [6.11391544342041], [4.963522911071777], [5.023489952087402], [6.226276397705078], [6.6125946044921875], [4.671811103820801], [4.748458385467529], [5.304233551025391], [7.430001258850098], [6.170243263244629], [4.8175048828125]]}"
     ]
    }
   ],
   "source": [
    "## Inferancing\n",
    "\n",
    "import mlflow\n",
    "\n",
    "model_uri = 'runs:/d2146b3db089413eabbba262dd9ba515/model'\n",
    "\n",
    "# Replace INPUT_EXAMPLE with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "input_data = test_x\n",
    "\n",
    "# Verify the model with the provided input data using the logged dependencies.\n",
    "# For more details, refer to:\n",
    "# https://mlflow.org/docs/latest/models.html#validate-models-before-deployment\n",
    "mlflow.models.predict(\n",
    "    model_uri=model_uri,\n",
    "    input_data=input_data,\n",
    "    env_manager=\"local\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a25830",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
